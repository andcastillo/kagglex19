{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.naive_bayes import GaussianNB\n#  importando los modulos confusion_matrix, roc_curve, auc, accuracy_score de sklearn.metrics\nfrom sklearn.metrics import confusion_matrix, roc_curve, auc, roc_auc_score, accuracy_score, classification_report\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":9,"outputs":[{"output_type":"stream","text":"/kaggle/input/datatn-bancolombia-2019/DT19_Datos_transaccionales_predict.csv\n/kaggle/input/datatn-bancolombia-2019/DT19_Datos_transaccionales_train.csv\n/kaggle/input/datatn-bancolombia-2019/Metadatos Datos_Var_Rpta.xlsx\n/kaggle/input/datatn-bancolombia-2019/DT19_IDs_predict.csv\n/kaggle/input/datatn-bancolombia-2019/Metadatos Datos_Trasaccionales.xlsx\n/kaggle/input/datatn-bancolombia-2019/Trminos y Condiciones Datatn 2019.pdf\n/kaggle/input/datatn-bancolombia-2019/presentacin Dataton BC 2019.pdf\n/kaggle/input/datatn-bancolombia-2019/DT19_maestro_cdgtrn_cdgrpta.csv\n/kaggle/input/datatn-bancolombia-2019/DT19_Datos_Var_Rpta_train_lite.csv\n/kaggle/input/datatn-bancolombia-2019/DT19_Datos_transaccionales_train_lite.csv\n/kaggle/input/datatn-bancolombia-2019/Metadatos maestro_cdgtrn_cdgrpta.xlsx\n/kaggle/input/datatn-bancolombia-2019/DT19_Datos_Var_Rpta_train.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"dataY = pd.read_csv('/kaggle/input/datatn-bancolombia-2019/DT19_Datos_Var_Rpta_train_lite.csv')\n","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataY.head()","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"   id  f_analisis  var_rpta  segmento\n0   1      201803         0         4\n1   2      201604         0         0\n2   3      201608         0         5\n3   4      201706         0         4\n4   5      201703         0         4","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>f_analisis</th>\n      <th>var_rpta</th>\n      <th>segmento</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>201803</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>201604</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>201608</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>201706</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>201703</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## lets try a very simple model"},{"metadata":{"trusted":true},"cell_type":"code","source":"colnames = data.columns.values.tolist()\npredictors = [colnames[3]]\ntargetName = colnames[2]","execution_count":16,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Very simple experimental setup"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a new array with the added features: features_two\n\nfeatures = dataY[predictors]\ntarget = dataY[targetName]\n# Split the data into train and test\ntrainX, testX, trainY, testY = train_test_split(features, target, test_size = 0.2, stratify = target )\nprint(trainX.shape, trainY.shape)\nprint(testX.shape, testY.shape)","execution_count":26,"outputs":[{"output_type":"stream","text":"(30400, 1) (30400,)\n(7600, 1) (7600,)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\nfrom sklearn.preprocessing import StandardScaler\n\n# NN is sensitive to data scale. We must normilize\nscaler = StandardScaler()  \ntrainXX = trainX.copy()\ntestXX = testX.copy()\n# Don't cheat - fit only on training data\nscaler.fit(trainX)  \ntrainXX = scaler.transform(trainXX)  \n# apply same transformation to test data\ntestXX = scaler.transform(testXX)  \n\nmodel3 = MLPClassifier(solver='lbfgs', alpha=1e-3, activation = 'logistic', max_iter=5000,\n                     hidden_layer_sizes = [10, 5, 3], verbose = True)\n\nmodel3.fit(trainXX, trainY)                         \n\n#Print the score on the train data\nprint(\"On training\")\nprint(model3.score(trainXX, trainY))\nprint(confusion_matrix(model3.predict(trainXX), trainY))\n\n#Print the score on the test data\nprint(\"\\nOn test\")\nprint(model3.score(testXX, testY))\nprint(confusion_matrix(model3.predict(testXX), testY))\n\nprint(\"ROC: \")\nprint(roc_auc_score(testY, model3.predict(testXX)))","execution_count":37,"outputs":[{"output_type":"stream","text":"On training\n0.9266776315789473\n[[28171  2229]\n [    0     0]]\n\nOn test\n0.9267105263157894\n[[7043  557]\n [   0    0]]\nROC: \n0.5\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Make a new prediction and save it in the output file"},{"metadata":{"trusted":true},"cell_type":"code","source":"data2 = pd.read_csv('/kaggle/input/datatn-bancolombia-2019/DT19_IDs_predict.csv')\n\n#Make a prediction\ndata2['probabilidad'] =  model3.predict(data2[['segmento']])\n\ndata_final = data2[['id', 'probabilidad']]\n\n# Save to a file. Find it in /kaggle/output/working/\ndata_final.to_csv(\"DT19_IDs_predict.csv\", index=False)\n","execution_count":54,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" model3.predict(data2[['segmento']])","execution_count":49,"outputs":[{"output_type":"execute_result","execution_count":49,"data":{"text/plain":"array([0, 0, 0, ..., 0, 0, 0])"},"metadata":{}}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}
